{"cells":[{"cell_type":"markdown","metadata":{"id":"_8xuLDv2I_CH"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rz3eMbi_JN-t"},"outputs":[],"source":["import random\n","import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import json\n","from statistics import mean\n","from dotenv import load_dotenv\n","import re\n","from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n","import openai\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oxHEWplE8dTb"},"outputs":[],"source":["# Load .env file with your API key\n","load_dotenv()\n","openai.api_key = os.getenv('OPENAI_API_KEY')"]},{"cell_type":"markdown","metadata":{"id":"ULH6BvTyhd6J"},"source":["# Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1717098831160,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":420},"id":"hpIpq-ACKM4Z","outputId":"010e14b3-723d-48e4-d8a1-1cd7b2d97d3e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["\"\"\"\n","Ouputs metrics for a series of predictions.\n","\n","predictions : array of tuples [(actual_value, predicted_value)...]\n","\"\"\"\n","def table_metrics(predictions):\n","    # Create a list of classes\n","    classes = sorted(set([x[0] for x in predictions] + [x[1] for x in predictions]), reverse=True)\n","    class_mapping = {label: idx for idx, label in enumerate(classes)}\n","\n","    actual_values = [class_mapping[item[0]] for item in predictions]\n","    predicted_values = [class_mapping[item[1]] for item in predictions]\n","\n","    return (f1_score(actual_values, predicted_values, average='micro'),\n","            f1_score(actual_values, predicted_values, average='macro'),\n","            precision_score(actual_values, predicted_values, average='macro'),\n","            recall_score(actual_values, predicted_values, average='macro'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YKa62piAsx02"},"outputs":[],"source":["# Perplexity calculations\n","! pip install tqdm\n","from tqdm import tqdm\n","import torch\n","from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n","\n","def perplexity(arr):\n","    device = 'cuda'\n","    model_id = 'gpt2-large'\n","    model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n","    tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n","    encodings = tokenizer('\\n\\n'.join(arr), return_tensors='pt')\n","\n","    max_length = model.config.n_positions\n","    stride = 512\n","\n","    lls = []\n","    for i in tqdm(range(0, encodings.input_ids.size(1), stride)):\n","        begin_loc = max(i + stride - max_length, 0)\n","        end_loc = i + stride\n","        input_ids = encodings.input_ids[:,begin_loc:end_loc].to(device)\n","        target_ids = input_ids.clone()\n","        target_ids[:,:-stride] = -100\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids, labels=target_ids)\n","            log_likelihood = outputs[0] * stride\n","\n","        lls.append(log_likelihood)\n","\n","    ppl = torch.exp(torch.stack(lls).sum() / i)\n","    return ppl"]},{"cell_type":"markdown","metadata":{"id":"qQ0Z6VHrg4Se"},"source":["# Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":794,"status":"ok","timestamp":1717098846514,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":420},"id":"Th7CWftQJtiN","outputId":"a05035dd-9f06-477d-e6a2-38a2113593c7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["# Load filtered negations\n","with open(f'../data/negations/negations_with_scores_gpt4.json') as f:\n","    items = json.load(f)\n","negation_to_claim = {}\n","results = []\n","for k in items:\n","    results.append((k, items[k][0], items[k][1]))\n","    negation_to_claim[items[k][0]] = k\n","\n","# negation set for processing\n","negations_set = set()\n","for result in results:\n","    if len(result[2]) < 4 and int(result[2]) >= 90:\n","        negations_set.add(result[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LM32s04EMx6V"},"outputs":[],"source":["supports = []\n","negations = []\n","counter = 0\n","corpus = {}\n","nei = 'NOT_ENOUGH_INFO' # Use 'UNRELATED' for ablation experiment\n","\n","# Prepare the dataset to iterate through\n","with open(f'../data/scitance/corpus.jsonl') as f_pdf:\n","    for line in f_pdf:\n","        pdf_parse_dict = json.loads(line)\n","        corpus[pdf_parse_dict['doc_id']] = pdf_parse_dict\n","print(\"Corpus parsed.\")\n","\n","# Load train data\n","train = {}\n","c_train = 0\n","s_train = 0\n","nei_train = 0\n","with open(f'../data/scitance/train.jsonl') as f_pdf:\n","    for line in f_pdf:\n","        parse = json.loads(line)\n","        for i in range(len(parse['doc_ids'])):\n","          if str(parse['doc_ids'][i]) in parse['evidence']:\n","            if parse['evidence'][str(parse['doc_ids'][i])][0]['label'] + 'S' == \"CONTRADICTS\" and parse['claim'] not in negations_set: ## negation checker\n","              counter += 1\n","              continue\n","            temp = {\n","                'claim': parse['claim'],\n","                'label': parse['evidence'][str(parse['doc_ids'][i])][0]['label'] + 'S'\n","            }\n","          else:\n","            temp = {\n","                'claim': parse['claim'],\n","                'label': nei\n","            }\n","            nei_train += 1\n","          train[parse['doc_ids'][i]] = temp\n","          if train[parse['doc_ids'][i]]['label'] == 'SUPPORTS':\n","              supports.append(train[parse['doc_ids'][i]]['claim'])\n","              s_train += 1\n","          if train[parse['doc_ids'][i]]['label'] == 'CONTRADICTS':\n","              negations.append(train[parse['doc_ids'][i]]['claim'])\n","              c_train += 1\n","print(\"\\nTrain parsed.\")\n","print('Supports: ', s_train)\n","print('Negations:', c_train)\n","print('NEI:\\t  ', nei_train)\n","\n","# Load dev data\n","dev = []\n","c_dev = 0\n","s_dev = 0\n","nei_dev = 0\n","with open(f'../data/scitance/dev.jsonl') as f_pdf:\n","    for line in f_pdf:\n","        parse = json.loads(line)\n","        for i in range(len(parse['doc_ids'])):\n","          if str(parse['doc_ids'][i]) in parse['evidence']:\n","            if parse['evidence'][str(parse['doc_ids'][i])][0]['label'] + 'S' == \"CONTRADICTS\" and parse['claim'] not in negations_set: ## negation checker\n","              counter += 1\n","              continue\n","            temp = {\n","                'claim': parse['claim'],\n","                'label': parse['evidence'][str(parse['doc_ids'][i])][0]['label'] + 'S',\n","                'id': parse['doc_ids'][i]\n","            }\n","          else:\n","            temp = {\n","                'claim': parse['claim'],\n","                'label': nei,\n","                'id': parse['doc_ids'][i]\n","            }\n","            nei_dev += 1\n","          dev.append(temp)\n","          if temp['label'] == 'SUPPORTS':\n","              supports.append(temp['claim'])\n","              s_dev += 1\n","          if temp['label'] == 'CONTRADICTS':\n","              negations.append(temp['claim'])\n","              c_dev += 1\n","print(\"\\nDev parsed.\")\n","print('Supports: ', s_dev)\n","print('Negations:', c_dev)\n","print('NEI:\\t  ', nei_dev)\n","\n","# Load test data\n","test = []\n","c_test = 0\n","s_test = 0\n","nei_test = 0\n","with open(f'../data/scitance/test.jsonl') as f_pdf:\n","    for line in f_pdf:\n","        parse = json.loads(line)\n","        for i in range(len(parse['doc_ids'])):\n","          if str(parse['doc_ids'][i]) in parse['evidence']:\n","            if parse['evidence'][str(parse['doc_ids'][i])][0]['label'] + 'S' == \"CONTRADICTS\" and parse['claim'] not in negations_set: ## negation checker\n","              counter += 1\n","              continue\n","            temp = {\n","                'claim': parse['claim'],\n","                'label': parse['evidence'][str(parse['doc_ids'][i])][0]['label'] + 'S',\n","                'id': parse['doc_ids'][i]\n","            }\n","          else:\n","            temp = {\n","                'claim': parse['claim'],\n","                'label': nei,\n","                'id': parse['doc_ids'][i]\n","            }\n","            nei_test += 1\n","          test.append(temp)\n","          if temp['label'] == 'SUPPORTS':\n","              supports.append(temp['claim'])\n","              s_test += 1\n","          if temp['label'] == 'CONTRADICTS':\n","              negations.append(temp['claim'])\n","              c_test += 1\n","print(\"\\nTest parsed.\")\n","print('Supports: ', s_test)\n","print('Negations:', c_test)\n","print('NEI:\\t  ', nei_test)\n","\n","print(\"\\nDataset Total:\")\n","print('Supports: ', len(supports))\n","print('Negations:', len(negations))\n","print(\"NEI:\\t  \", str(nei_train + nei_dev + nei_test))\n","print(\"\\n\" + str(counter), \"negations removed from filtering.\")\n","\n","# Create a dict for ease of random sampling in multi-shot ICL\n","train_supports = {}\n","train_contradicts = {}\n","train_nei = {}\n","for key in train.keys():\n","  if train[key]['label'] == 'SUPPORTS':\n","    train_supports[key] = train[key]\n","  if train[key]['label'] == 'CONTRADICTS':\n","    train_contradicts[key] = train[key]\n","  if train[key]['label'] == nei:\n","    train_nei[key] = train[key]"]},{"cell_type":"markdown","metadata":{"id":"1xTIxuNascXt"},"source":["# Perplexity testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqqk1bhaTu9c"},"outputs":[],"source":["device = 'cuda'\n","model_id = 'gpt2-large'\n","model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n","tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n","from scipy import stats"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":11291,"status":"ok","timestamp":1711659624801,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":420},"id":"kbCwEdqdAi2A","outputId":"6e514b17-d1f8-47fc-cc19-8e7fe903d606"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["citance_perplexity = []\n","for x in supports:\n","    encodings = tokenizer(x, return_tensors=\"pt\")\n","\n","    input_ids = encodings.input_ids.to(device)\n","    target_ids = input_ids.clone()\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids, labels=target_ids)\n","        neg_log_likelihood = outputs.loss\n","\n","    citance_perplexity.append(neg_log_likelihood)\n","citance_perplexity = [x.item() for x in citance_perplexity]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":7534,"status":"ok","timestamp":1711659632331,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":420},"id":"C5hcrpk8DHAn","outputId":"5b1ec723-2867-457d-f8bf-f95bdbc5c7db"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["negation_perplexity = []\n","for x in negations:\n","    encodings = tokenizer(x, return_tensors=\"pt\")\n","\n","    input_ids = encodings.input_ids.to(device)\n","    target_ids = input_ids.clone()\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids, labels=target_ids)\n","        neg_log_likelihood = outputs.loss\n","\n","    negation_perplexity.append(neg_log_likelihood)\n","negation_perplexity = [x.item() for x in negation_perplexity]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tG5m1J-dDkdn"},"outputs":[],"source":["plt.hist(citance_perplexity, bins=20, color='skyblue', alpha=0.5, label='Distribution 1', edgecolor='black')\n","plt.hist(negation_perplexity, bins=20, color='salmon', alpha=0.5, label='Distribution 2', edgecolor='black')\n","plt.xlabel('Perplexity Values')\n","plt.ylabel('Frequency')\n","plt.title('Citance and Negation Perplexity')\n","plt.legend(('Citances', 'Negations'), loc='upper right');\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zGsjbYOSFdSq"},"outputs":[],"source":["print(\"Min:\", round(np.min(citance_perplexity), 3), \"\\t\", round(np.min(negation_perplexity), 3))\n","print(\"Q1: \", round(np.percentile(citance_perplexity, 25), 3), \"\\t\", round(np.percentile(negation_perplexity, 25), 3))\n","print(\"Med:\", round(np.median(citance_perplexity), 3), \"\\t\", round(np.median(negation_perplexity), 3))\n","print(\"Q3: \", round(np.percentile(citance_perplexity, 75), 3), \"\\t\", round(np.percentile(negation_perplexity, 75), 3))\n","print(\"Max:\", round(np.max(citance_perplexity), 3), \"\\t\", round(np.max(negation_perplexity), 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vMUA4ExTTgS"},"outputs":[],"source":["t_statistic, p_value = stats.ttest_ind(citance_perplexity, negation_perplexity)\n","print(\"T-statistic:\", t_statistic)\n","print(\"P-value:\", p_value)\n","stats.ttest_ind(citance_perplexity, negation_perplexity).confidence_interval()"]},{"cell_type":"markdown","metadata":{"id":"KyfSw4kjoe12"},"source":["# Run experiments"]},{"cell_type":"markdown","metadata":{"id":"fr_TT0I7oq_q"},"source":["## 1. Zero-shot / claim only / no NEI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":1279821,"status":"ok","timestamp":1707182053020,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":480},"id":"TS1UFTAgolSb","outputId":"35729dcb-85a5-4cf9-955e-28c8ffd7b0ee"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["for i in range(5):\n","    random.seed(22)\n","    query = \"Given a claim, please determine whether the existing academic literature SUPPORTS or CONTRADICTS the claim (even if you cannot reference specific abstracts). Please return your answer as only the capitalized token, as well as an explanation or rationale for the answer. \\n\\tClaim: {}\"\n","    results = []\n","    for item in test:\n","        key = item['id']\n","        abstract = corpus[key]['abstract']\n","        claim = item['claim']\n","        label = item['label']\n","        if label == nei:\n","          continue\n","        query_string = query.format(claim)\n","        message = [{\"role\": \"user\", \"content\": query_string}]\n","        try:\n","          response = openai.ChatCompletion.create(model=\"gpt-4\", messages=message, temperature=0.2)\n","        except Exception as e:\n","          print(e)\n","          continue\n","        predicted = response.choices[0].message.content\n","        results.append((label, predicted))\n","    obj = json.dumps(results, indent=4)\n","    with open(f'../data/results/zero_claim_only_no_nei/zero_claim_only_no_nei_{i}.json', 'w') as f:\n","      f.write(obj)"]},{"cell_type":"markdown","metadata":{"id":"mDnAeTT4uLYU"},"source":["## 2. Zero-shot / claim and abstract / no NEI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBsWcC1KuRHe"},"outputs":[],"source":["for i in range(5):\n","    random.seed(22)\n","    query = \"Please obey the following: With a specific abstract, please make an estimation whether the abstract SUPPORTS or CONTRADICTS the claim. You must choose SUPPORTS or CONTRADICTS. Please return your answer as only the capitalized token, as well as an explanation or rationale for the answer. \\nAbstract: {}\\n\\tClaim: {}\"\n","    results = []\n","    for item in test:\n","        key = item['id']\n","        abstract = corpus[key]['abstract']\n","        claim = item['claim']\n","        label = item['label']\n","        if label == nei:\n","          continue\n","        query_string = query.format(abstract, claim)\n","        message = [{\"role\": \"user\", \"content\": query_string}]\n","        try:\n","          response = openai.ChatCompletion.create(model=\"gpt-4\", messages=message, temperature=0.2)\n","        except Exception as e:\n","          print(e)\n","          continue\n","        predicted = response.choices[0].message.content\n","        results.append((label, predicted))\n","    obj = json.dumps(results, indent=4)\n","    with open(f'../data/results/zero_with_abstract_no_nei/zero_with_abstract_no_nei_{i}.json', 'w') as f:\n","        f.write(obj)"]},{"cell_type":"markdown","metadata":{"id":"nfsFuE9ZoxRY"},"source":["## 3. Zero-shot / claim and abstract / with NEI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":1659141,"status":"ok","timestamp":1716964448524,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":420},"id":"BuDjb1tFo07h","outputId":"dd90b3a5-9c50-4d74-a2de-6e81bd8f6318"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["for i in range(5):\n","    random.seed(22)\n","    query = \"Please obey the following: With a specific abstract, please make an estimation whether the abstract SUPPORTS or CONTRADICTS the claim, or if there is NOT_ENOUGH_INFO to determine. You must choose SUPPORTS or CONTRADICTS or NOT_ENOUGH_INFO. Please return your answer as only the capitalized token(s), as well as an explanation or rationale for the answer. \\nAbstract: {}\\n\\tClaim: {}\"\n","    # query = \"Please obey the following: With a specific abstract, please make an estimation whether the abstract SUPPORTS, CONTRADICTS, or is UNRELATED to the claim. You must choose SUPPORTS or CONTRADICTS or UNRELATED. Please return your answer as only the capitalized token, as well as an explanation or rationale for the answer. \\nAbstract: {}\\n\\tClaim: {}\"\n","    results = []\n","    for item in test:\n","        time.sleep(2)\n","        key = item['id']\n","        abstract = corpus[key]['abstract']\n","        claim = item['claim']\n","        label = item['label']\n","        query_string = query.format(abstract, claim)\n","        message = [{\"role\": \"user\", \"content\": query_string}]\n","        try:\n","          response = openai.ChatCompletion.create(model=\"gpt-4\", messages=message, temperature=0.2)\n","        except Exception as e:\n","          print(e)\n","          continue\n","        predicted = response.choices[0].message.content\n","        results.append((label, predicted))\n","    obj = json.dumps(results, indent=4)\n","    with open(f'../data/results/zero_with_abstract_with_nei/zero_with_abstract_with_nei_{i}.json', 'w') as f:\n","        f.write(obj)"]},{"cell_type":"markdown","metadata":{"id":"NYUwbDq6o1sJ"},"source":["## 4. Few-shot / claim only / no NEI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":1293384,"status":"ok","timestamp":1707263610695,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":480},"id":"rk_plDpwo7ON","outputId":"f3e8d49c-1a5b-45e2-f86b-8e7567ac6b48"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["for i in range(5):\n","    random.seed(22)\n","    intro = \"The following are examples of claims from a research paper and the corresponding abstract from the paper they are citing.\"\n","    supports =  \"\\nThis is an example of an abstract that SUPPORTS the claim: \\n\\tSupporting abstract: {} \\n\\tClaim: {}\"\n","    contradicts = \"\\nThis is an example of an abstract that CONTRADICTS the claim: \\n\\tContradicting abstract: {} \\n\\tClaim: {}\"\n","    query = \"Please obey the following: With no specific abstracts, please make an estimation whether the existing academic literature (and not the abstracts above) SUPPORTS or CONTRADICTS the claim. You must choose SUPPORTS or CONTRADICTS. Please return your answer as only the capitalized token, as well as an explanation or rationale for the answer. \\n\\tClaim: {}\"\n","    results = []\n","    for item in test:\n","        time.sleep(5.5)\n","        key = item['id']\n","        abstract = corpus[key]['abstract']\n","        claim = item['claim']\n","        label = item['label']\n","        if label == nei:\n","          continue\n","        query_string = query.format(claim)\n","\n","        k, v = random.choice(list(train_supports.items()))\n","        supports_claim = v['claim']\n","        supports_abstract = corpus[k]['abstract']\n","        supports_string = supports.format(supports_abstract, supports_claim)\n","\n","        k, v = random.choice(list(train_contradicts.items()))\n","        contradicts_claim = v['claim']\n","        contradicts_abstract = corpus[k]['abstract']\n","        contradicts_string = contradicts.format(contradicts_abstract, contradicts_claim)\n","\n","        temp = [supports_string, contradicts_string]\n","        random.shuffle(temp)\n","        prompt = intro + temp[0] + temp[1] + query_string\n","        message = [{\"role\": \"user\", \"content\": prompt}]\n","        try:\n","          response = openai.ChatCompletion.create(model=\"gpt-4\", messages=message, temperature=0.2)\n","        except Exception as e:\n","          print(e)\n","          continue\n","        predicted = response.choices[0].message.content\n","        results.append((label, predicted))\n","    obj = json.dumps(results, indent=4)\n","    with open(f'../data/results/few_claim_only_no_nei/few_claim_only_no_nei_{i}.json', 'w') as f:\n","        f.write(obj)"]},{"cell_type":"markdown","metadata":{"id":"yk_U4hLDo8Kd"},"source":["## 5. Few-shot / claim and abstract / no NEI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":4524730,"status":"ok","timestamp":1707291225817,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":480},"id":"IkccZO-uo-kc","outputId":"52a52a8b-7db7-495f-b277-47841f2e5ab2"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["for i in range(5):\n","    random.seed(22)\n","    intro = \"The following are examples of claims from a research paper and the corresponding abstract from the paper they are citing.\"\n","    supports =  \"\\nThis is an example of an abstract that SUPPORTS the claim: \\n\\tSupporting abstract: {} \\n\\tClaim: {}\"\n","    contradicts = \"\\nThis is an example of an abstract that CONTRADICTS the claim: \\n\\tContradicting abstract: {} \\n\\tClaim: {}\"\n","    query = \"\\nPlease obey the following: given a new abstract and claim pair, please make an estimation whether the abstract SUPPORTS or CONTRADICTS the claim. You must choose SUPPORTS or CONTRADICTS. Please return your answer as the capitalized token, as well as an explanation or rationale for the answer. \\n\\tNew abstract: {} \\n\\tClaim: {}\"\n","    results = []\n","    for item in test:\n","        time.sleep(5.5)\n","        key = item['id']\n","        abstract = corpus[key]['abstract']\n","        claim = item['claim']\n","        label = item['label']\n","        if label == nei:\n","          continue\n","        query_string = query.format(abstract, claim)\n","\n","        k, v = random.choice(list(train_supports.items()))\n","        supports_claim = v['claim']\n","        supports_abstract = corpus[k]['abstract']\n","        supports_string = supports.format(supports_abstract, supports_claim)\n","\n","        k, v = random.choice(list(train_contradicts.items()))\n","        contradicts_claim = v['claim']\n","        contradicts_abstract = corpus[k]['abstract']\n","        contradicts_string = contradicts.format(contradicts_abstract, contradicts_claim)\n","\n","        temp = [supports_string, contradicts_string]\n","        random.shuffle(temp)\n","        prompt = intro + temp[0] + temp[1] + query_string\n","        message = [{\"role\": \"user\", \"content\": prompt}]\n","        try:\n","          response = openai.ChatCompletion.create(model=\"gpt-4\", messages=message, temperature=0.2)\n","        except Exception as e:\n","          print(e)\n","          continue\n","        predicted = response.choices[0].message.content\n","        results.append((label, predicted))\n","    obj = json.dumps(results, indent=4)\n","    with open(f'../data/results/few_with_abstract_no_nei/few_with_abstract_no_nei_{i}.json', 'w') as f:\n","      f.write(obj)"]},{"cell_type":"markdown","metadata":{"id":"XOUMxO58uJVX"},"source":["## 6. Few-shot / claim and abstract / with NEI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3294254,"status":"ok","timestamp":1717102218986,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":420},"id":"GUUzUxNwuiXD","outputId":"7e24599d-e6c3-4d69-92da-db947cf633fc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["for i in range(5):\n","    random.seed(22)\n","    intro = \"The following are examples of claims from a research paper and the corresponding abstract from the paper they are citing.\"\n","    supports =  \"\\nThis is an example of an abstract that SUPPORTS the claim: \\n\\tSupporting abstract: {} \\n\\tClaim: {}\"\n","    contradicts = \"\\nThis is an example of an abstract that CONTRADICTS the claim: \\n\\tContradicting abstract: {} \\n\\tClaim: {}\"\n","    # unrelated = \"\\nThis is an example of an abstract that is UNRELATED to the claim: \\n\\tUnrelated abstract: {} \\n\\tClaim: {}\"\n","    # query = \"\\nPlease obey the following: given a new abstract and claim pair, please make an estimation whether the abstract SUPPORTS, CONTRADICTS, or is UNRELATED to the claim. You must choose SUPPORTS or CONTRADICTS or UNRELATED. Please return your answer as the capitalized token, as well as an explanation or rationale for the answer. \\n\\tNew abstract: {} \\n\\tClaim: {}\"\n","    nei = \"\\nThis is an example of an abstract with NOT_ENOUGH_INFO about the claim: \\n\\tMissing info abstract: {} \\n\\tClaim: {}\"\n","    query = \"\\nPlease obey the following: given a new abstract and claim pair, please make an estimation whether the abstract SUPPORTS or CONTRADICTS the claim, or if there is NOT_ENOUGH_INFO to determine. You must choose SUPPORTS or CONTRADICTS or NOT_ENOUGH_INFO. Please return your answer as the capitalized token(s), as well as an explanation or rationale for the answer. \\n\\tNew abstract: {} \\n\\tClaim: {}\"\n","\n","    results = []\n","    for item in test:\n","        time.sleep(5.5)\n","        key = item['id']\n","        abstract = corpus[key]['abstract']\n","        claim = item['claim']\n","        label = item['label']\n","        query_string = query.format(abstract, claim)\n","\n","        k, v = random.choice(list(train_supports.items()))\n","        supports_claim = v['claim']\n","        supports_abstract = corpus[k]['abstract']\n","        supports_string = supports.format(supports_abstract, supports_claim)\n","\n","        k, v = random.choice(list(train_contradicts.items()))\n","        contradicts_claim = v['claim']\n","        contradicts_abstract = corpus[k]['abstract']\n","        contradicts_string = contradicts.format(contradicts_abstract, contradicts_claim)\n","\n","        k, v = random.choice(list(train_nei.items()))\n","        nei_claim = v['claim']\n","        nei_abstract = corpus[k]['abstract']\n","        unrelated_string = nei.format(nei_abstract, nei_claim)\n","\n","        temp = [supports_string, contradicts_string, unrelated_string]\n","        random.shuffle(temp)\n","        prompt = intro + temp[0] + temp[1] + temp[2] + query_string\n","        message = [{\"role\": \"user\", \"content\": prompt}]\n","        try:\n","          response = openai.ChatCompletion.create(model=\"gpt-4\", messages=message, temperature=0.2)\n","        except Exception as e:\n","          print(e)\n","          continue\n","        predicted = response.choices[0].message.content\n","        results.append((label, predicted))\n","    obj = json.dumps(results, indent=4)\n","    with open(f'../data/results/nei_ablation/few_with_abstract_with_nei/few_with_abstract_with_nei_{i}.json', 'w') as f:\n","      f.write(obj)"]},{"cell_type":"markdown","metadata":{"id":"B7bj48WuG6IB"},"source":["\n","# Calculate metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":192,"status":"ok","timestamp":1716339845901,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":420},"id":"B6BPm_dQei_t","outputId":"96d54b2d-5aff-4bb9-c07f-f91ef65256cb"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Define experiments to calculate results for\n","exps = ['zero_claim_only_no_unrelated',\n","        'zero_with_abstract_no_unrelated',\n","        'zero_with_abstract_with_unrelated',\n","        'multi_claim_only_no_unrelated',\n","        'multi_with_abstract_no_unrelated',\n","        'multi_with_abstract_with_unrelated',\n","        'scifact_baseline'\n","        ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsD4t4YLfhoz"},"outputs":[],"source":["# Calculate metrics for each experiment\n","results = {}\n","for exp in exps:\n","    final_avgs = []\n","    abstentions = 0\n","    total = 0\n","    for i in range(5):\n","        with open('../data/results/' + exp + \"/\" + exp + f'_{i}.json') as f:\n","            items = json.load(f)\n","        if 'no_nei' in exp:\n","            labels = ['CONTRADICTS', 'SUPPORTS']\n","        else:\n","            labels = ['CONTRADICTS', 'SUPPORTS', nei]\n","        data = []\n","        # Iterate over each each response from the experiment\n","        for x in items:\n","            total += 1\n","            # Search for the label in the first ten words\n","            label = x[1].split()[:10]\n","            matched = False\n","            for potential_label in labels:\n","                if potential_label in [re.sub(r'[^\\w\\s]', '', x) for x in label]:\n","                    label = potential_label\n","                    matched = True\n","                    break\n","            if not matched:\n","                abstentions += 1\n","                label = 'ABSTENTION'\n","            data.append((x[0], label))\n","        # Calculate metrics and add experiment to results dict\n","        final_avgs.append(table_metrics(data))\n","        temp = [mean([x[n] for x in final_avgs]) for n in range(len(final_avgs[0]))]\n","        temp.append((abstentions, total))\n","        results[exp] = temp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-zViaBDRlJDG"},"outputs":[],"source":["\"\"\"\n","Display results per experiment in the format:\n","\n","Micro F1\n","Macro F1\n","Macro Precision\n","Macro Recall\n","(abstentions, total)\n","\"\"\"\n","results"]},{"cell_type":"markdown","metadata":{"id":"Ooo2hlpNXwfB"},"source":["# Baseline on SciFact test set"]},{"cell_type":"markdown","source":["## Load data"],"metadata":{"id":"LZmBZhjw8aum"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":2475,"status":"ok","timestamp":1716844696223,"user":{"displayName":"Maxwell Bennett","userId":"03923987871652972769"},"user_tz":420},"id":"UEhz2ny_X2Ks","outputId":"f0fc969e-84c4-4d37-810e-ffbca84e0147"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["path_to_scifact_corpus = '' # Download SciFact and add file path (corpus.jsonl)\n","\n","with open(path_to_scifact_corpus) as f_pdf:\n","    for line in f_pdf:\n","        pdf_parse_dict = json.loads(line)\n","        corpus[pdf_parse_dict['doc_id']] = pdf_parse_dict\n","\n","\n","path_to_scifact_predictions_topk '' # Use BEIR to retrieve top-k predicitons\n","\n","test = []\n","with open(path_to_scifact_predictions_topk) as f_pdf:\n","    for line in f_pdf:\n","        parse = json.loads(line)\n","        for id in parse['cited_doc_ids']:\n","            test.append({\n","                'claim': parse['claim'],\n","                'id': id,\n","                'claim_id': parse['id']\n","            })"]},{"cell_type":"code","source":["#### SCitance ICL - comment out if using SciFact ICL\n","train = []\n","with open(f'../data/dataset/train.jsonl') as f_pdf:\n","    for line in f_pdf:\n","        parse = json.loads(line)\n","        for i in range(len(parse['doc_ids'])):\n","          if str(parse['doc_ids'][i]) in parse['evidence']:\n","            if parse['evidence'][str(parse['doc_ids'][i])][0]['label'] + 'S' == \"CONTRADICTS\" and parse['claim'] not in negations_set: ## negation checker\n","              continue\n","            temp = {\n","                'claim': parse['claim'],\n","                'label': parse['evidence'][str(parse['doc_ids'][i])][0]['label'] + 'S',\n","                'id': str(parse['doc_ids'][i])\n","            }\n","          else:\n","            temp = {\n","                'claim': parse['claim'],\n","                'label': \"NOT_ENOUGH_INFO\",\n","                'id': str(parse['doc_ids'][i])\n","            }\n","          train.append(temp)"],"metadata":{"id":"IZ4G-J72JGnT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #### SciFact ICL - comment out if using SCitance ICL\n","# train = []\n","# path_to_scifact_training_claims = '' # Download and add path to claims in SciFact's train set\n","# with open(path_to_scifact_training_claims) as f_pdf:\n","#     for line in f_pdf:\n","#         parse = json.loads(line)\n","#         # {'id': 0, 'claim': '0-dimensional biomaterials lack inductive properties.', 'evidence': {}, 'cited_doc_ids': [31715818]}\n","#         for id in parse['cited_doc_ids']:\n","#           if str(id) not in parse['evidence']:\n","#             train.append({\n","#                 'claim': parse['claim'],\n","#                 'label': \"NOT_ENOUGH_INFO\",\n","#                 'id': id\n","#             })\n","#           else:\n","#             train.append({\n","#                 'claim': parse['claim'],\n","#                 'label': parse['evidence'][str(id)][0]['label'] + \"S\",\n","#                 'id': id\n","#             })"],"metadata":{"id":"eNtQuLLmJHek"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_supports = []\n","train_contradicts = []\n","train_nei = []\n","for item in train:\n","  if item['label'] == 'SUPPORTS':\n","    train_supports.append(item)\n","  if item['label'] == 'CONTRADICTS':\n","    train_contradicts.append(item)\n","  if item['label'] == \"NOT_ENOUGH_INFO\":\n","    train_nei.append(item)"],"metadata":{"id":"HnMl8UY_JHyC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run SciFact experiment"],"metadata":{"id":"3DGB5_9u8ViG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3wl_9HP9X4jB"},"outputs":[],"source":["random.seed(22)\n","\n","intro = \"The following are examples of claims from a research paper and the corresponding abstract from the paper they are citing.\"\n","supports =  \"\\nThis is an example of an abstract that SUPPORTS the claim: \\n\\tSuppporting abstract: {} \\n\\tClaim: {}\"\n","contradicts = \"\\nThis is an example of an abstract that CONTRADICTS the claim: \\n\\tContradicting abstract: {} \\n\\tClaim: {}\"\n","unrelated = \"\\nThis is an example of an abstract with NOT_ENOUGH_INFO about the claim: \\n\\tMissing info abstract: {} \\n\\tClaim: {}\"\n","\n","# Zero shot\n","# query = \"Please obey the following: given a new abstract and claim pair, please make an estimation whether the abstract SUPPORTS or CONTRADICTS the claim, or if there is NOT_ENOUGH_INFO to determine. You must choose SUPPORTS or CONTRADICTS or NOT_ENOUGH_INFO. Please return your answer with the capitalized token(s) at the beginning of the response. Also provide an explanation or rationale for the answer. \\n\\tAbstract: {} \\n\\tClaim: {}\"\n","\n","# Few shot\n","query = \"\\nPlease obey the following: With a specific abstract, please make an estimation whether the abstract SUPPORTS, CONTRADICTS, or if there is NOT_ENOUGH_INFO to determine. You must choose SUPPORTS or CONTRADICTS or NOT_ENOUGH_INFO. Please return your answer as only the capitalized token, as well as an explanation or rationale for the answer. \\n\\tAbstract: {} \\n\\tClaim: {}\"\n","\n","results = []\n","errors = 0\n","\n","for item in test:\n","    time.sleep(5)\n","    doc_id = item['id']\n","    claim_id = item['claim_id']\n","    abstract = corpus[doc_id]['abstract']\n","    claim = item['claim']\n","    query_string = query.format(abstract, claim)\n","\n","    # Few shot\n","    v = random.choice(train_supports)\n","    supports_claim = v['claim']\n","    supports_abstract = corpus[int(v['id'])]['abstract']\n","    supports_string = supports.format(supports_abstract, supports_claim)\n","\n","    v = random.choice(train_contradicts)\n","    contradicts_claim = v['claim']\n","    contradicts_abstract = corpus[int(v['id'])]['abstract']\n","    contradicts_string = contradicts.format(contradicts_abstract, contradicts_claim)\n","\n","    v = random.choice(train_nei)\n","    nei_claim = v['claim']\n","    nei_abstract = corpus[int(v['id'])]['abstract']\n","    unrelated_string = unrelated.format(nei_abstract, nei_claim)\n","\n","    temp = [supports_string, contradicts_string, unrelated_string]\n","    random.shuffle(temp)\n","    prompt = intro + temp[0] + temp[1] + temp[2] + query_string\n","\n","    # Zero shot\n","    # prompt = query_string\n","    message = [{\"role\": \"user\", \"content\": prompt}]\n","    try:\n","        response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo-0125\", messages=message, temperature=0.2)\n","    except Exception as e:\n","        print(e)\n","        errors += 1\n","        continue\n","\n","    predicted = response.choices[0].message.content\n","    result = (claim_id, doc_id, predicted)\n","    results.append(result)\n","obj = json.dumps(results, indent=4)\n","with open('./data/results/scifact_test/our_icl_0_gpt3-5.json', \"w\") as f:\n","        f.write(obj)\n","print(\"Finished!\")\n","print(\"OpenAI API Errors:\", errors)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["_8xuLDv2I_CH","ULH6BvTyhd6J","1xTIxuNascXt","KyfSw4kjoe12","B7bj48WuG6IB","3DGB5_9u8ViG"],"gpuType":"T4","provenance":[{"file_id":"1tZHXDLsrAXuT4OoyvaDpzz4E4gOzRKrY","timestamp":1720033133765}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}